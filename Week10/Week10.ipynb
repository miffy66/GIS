{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日本とメッシュ\n",
    "\n",
    "In the US, space is divided by \"census tracts,\" a division created by the census bureau based on population counts. Census tract boundaries change every 10 years, making it difficult to measure change over time.\n",
    "\n",
    "In contrast, Japan uses \"meshes\" which is a grid-based division of space. Population statistics are summarized by these meshes, which scale depending on the level of geography you are studying.\n",
    "\n",
    "米国では、空間は「国勢調査区」によって分割されており、これは国勢調査局が人口数に基づいて作成した区画です。 国勢調査区域の境界は 10 年ごとに変化するため、時間の経過に伴う変化を測定することが困難になります。\n",
    "\n",
    "対照的に、日本ではグリッドベースの空間分割である「メッシュ」が使用されます。 人口統計はこれらのメッシュによって要約され、調査している地理のレベルに応じてスケールが変わります。\n",
    "\n",
    "<img src=\"https://www.stat.go.jp/data/mesh/img/map1.jpg\">\n",
    "\n",
    "[Figure about shows how grids are laid out in metropolitan Tokyo region. Source:総務省統計局](https://www.stat.go.jp/data/mesh/teiky_3.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## そもそもメッシュとは？\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yohman/23-1-Reitaku-GIS/main/Weeks/Week10/images/japan%20mesh%20scales.png\" width=800>\n",
    "\n",
    "メッシュがどのように機能するかを理解するには、インタラクティブな Web マップでメッシュを体験するのが最善です。 国土地理院は、メッシュのオン/オフを切り替えるオプションを備えたインタラクティブなマップを提供しています。\n",
    "\n",
    "➡️ [地理院地図](https://maps.gsi.go.jp/#5/36.104611/140.084556/&base=std&ls=std&disp=1&vs=c1g1j0h0k0l0u0t0z0r0s0m0f1)\n",
    "\n",
    "➡️ ⚙️設定\n",
    "\n",
    "➡️ グリッド表示\n",
    "\n",
    "➡️ 地域メッシュ🔛"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メッシュでマップ\n",
    "\n",
    "日本のメッシュがどのように機能するかを新たに理解したら、都道府県の人口マップを作成してみましょう。 1kmメッシュグリッドを使用します。 ワークフローは次のとおりです。\n",
    "\n",
    "1. eStat Web サイトから、千葉県の 1km メッシュ グリッド (4 つ) を検索してダウンロード\n",
    "2. 同じ Web サイトから、同じ地域とメッシュ サイズの人口統計をダウンロード\n",
    "3. データをインポートして結合します。 これをメッシュと統計データの両方に対して行う\n",
    "4. データのクリーンアップ。 これを避けることはできないステップである😕\n",
    "5. 統計データをメッシュ データに結合する\n",
    "6. 美しい地図を作成！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import contextily as ctx\n",
    "import plotly.express as px\n",
    "import contextily as cx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set font\n",
    "import matplotlib as mpl\n",
    "\n",
    "# for Mac\n",
    "mpl.rc('font',family='Hiragino Maru Gothic Pro')\n",
    "\n",
    "# for PC\n",
    "# mpl.rc('font',family='MS Gothic')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eStat Web サイトから、千葉県の 1km メッシュ グリッド (4 つ) を検索してダウンロード"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ https://www.e-stat.go.jp/\n",
    "\n",
    "➡️ 地図\n",
    "\n",
    "➡️ 統計データダウンロード\n",
    "\n",
    "➡️ 境界データ\n",
    "\n",
    "➡️ 3次メッシュ（1kmメッシュ）\n",
    "\n",
    "➡️ 世界測地系緯度経度・Shapefile\n",
    "\n",
    "➡️ 都道府県で絞込み\n",
    "\n",
    "➡️ 12 千葉県 (チェック)\n",
    "\n",
    "➡️ M5239, M5240, M5339, M5340 をそれぞれダウンロード\n",
    "\n",
    "➡️ 新しいフォルダー【data】を作成\n",
    "\n",
    "➡️ ダウンロードしたファイル[SDDSW5239.zip, SDDSW5240.zip, SDDSW5339.zip, SDDSW5340.zip,]を data フォルダーに移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "'/vsizip/data/SDDSWS5239.zip' does not exist in the file system, and is not recognized as a supported dataset name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: '/vsizip/data/SDDSWS5239.zip' does not exist in the file system, and is not recognized as a supported dataset name.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 空間データなので geopandas (gpd) でインポート\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m chibamesh1 \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/SDDSWS5239.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m chibamesh2 \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/SDDSWS5240.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m chibamesh3 \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/SDDSWS5339.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gis/lib/python3.11/site-packages/geopandas/io/file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gis/lib/python3.11/site-packages/geopandas/io/file.py:338\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    339\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gis/lib/python3.11/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gis/lib/python3.11/site-packages/fiona/__init__.py:292\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    304\u001b[0m         path,\n\u001b[1;32m    305\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gis/lib/python3.11/site-packages/fiona/collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:588\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: '/vsizip/data/SDDSWS5239.zip' does not exist in the file system, and is not recognized as a supported dataset name."
     ]
    }
   ],
   "source": [
    "# 空間データなので geopandas (gpd) でインポート\n",
    "\n",
    "chibamesh1 = gpd.read_file('data/SDDSWS5239.zip')\n",
    "chibamesh2 = gpd.read_file('data/SDDSWS5240.zip')\n",
    "chibamesh3 = gpd.read_file('data/SDDSWS5339.zip')\n",
    "chibamesh4 = gpd.read_file('data/SDDSWS5340.zip')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四つのファイルを統合する\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yohman/23-1-Reitaku-GIS/main/Weeks/Week10/images/chibamesh.png\" width=600>\n",
    "\n",
    "4つのメッシュgeodataが揃った。では統合しましょう。空間データを統合するには geopandas の `gpd.pd.concat()` 関数を使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all four mesh shapes\n",
    "chibamesh = gpd.pd.concat([chibamesh1,chibamesh2,chibamesh3,chibamesh4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plot\n",
    "chibamesh.plot(figsize=(20,20),edgecolor='white',linewidth=0.1,column='MESH1_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chibamesh.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人口統計をダウンロード\n",
    "\n",
    "では４つのメッシュ（5339,5340,5239,5240) に当てはまる人口統計データをダウンロードしましょう。\n",
    "\n",
    "➡️ https://www.e-stat.go.jp/\n",
    "\n",
    "➡️ 地図\n",
    "\n",
    "➡️ 統計データダウンロード\n",
    "\n",
    "➡️ 統計データ\n",
    "\n",
    "➡️ 国勢調査\n",
    "\n",
    "➡️ 2020年\n",
    "\n",
    "➡️ 3次メッシュ（1kmメッシュ）\n",
    "\n",
    "➡️ 人口及び世帯\n",
    "\n",
    "➡️ メッシュコードで絞込み（左欄）\n",
    "\n",
    "➡️ M5239, M5240, M5339, M5340 をそれぞれチェックして選択ボタン\n",
    "\n",
    "➡️ 定義書（PDF)をダウンロード（大事）\n",
    "\n",
    "➡️ それぞれのCSVファイルをダウンロード\n",
    "\n",
    "➡️ ダウンロードしたファイル[tblT001100S5239.zip, tblT001100S5240.zip, tblT001100S5339.zip, tblT001100S5340.zip,]を data フォルダーに移動\n",
    "\n",
    "前回は、ファイルを展開しなければいけないと思ったのですが、pandas は圧縮ファイルを読み込めることが判明したので、展開する必要はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvデータなので pandas (pd) でインポート\n",
    "# 文字化け予防のために encoding='cp932' \n",
    "chibadata1 = pd.read_csv('data/tblT001100S5239.zip', encoding='cp932')\n",
    "chibadata4 = pd.read_csv('data/tblT001100S5340.zip', encoding='cp932')\n",
    "chibadata2 = pd.read_csv('data/tblT001100S5240.zip', encoding='cp932')\n",
    "chibadata3 = pd.read_csv('data/tblT001100S5339.zip', encoding='cp932')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義書を確認\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yohman/23-1-Reitaku-GIS/main/Weeks/Week10/images/metadata.png\">\n",
    "\n",
    "「連番」列は、ダウンロードしたデータに存在するフィールド名を示します。 これらのフィールド名は、その変数のコロプレス マップを作成するために使用されます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "chibadata4.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータには 2 つの問題があります。\n",
    "\n",
    "まず、最初の行には説明テキストが含まれている（人口（総数）など）。 これは、列を数値にする必要がある統計マップを作成する場合に問題を引き起こします。\n",
    "\n",
    "次に、データに「*」が含まれている。 これも数字以外の文字であるため、問題が発生します。\n",
    "\n",
    "これらに一つ一つ対処していく必要がある。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題１：１行目を削除\n",
    "さ、ここで課題です。４つのテーブルから１行目を削除してください。Googleで検索したり、ChatGPTに相談したり、隣の人と話してもオッケー！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ４つのテーブルから１行目を削除\n",
    "chibadata1 = chibadata1[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ４つのテーブルから１行目を削除\n",
    "chibadata2 = chibadata2[1:]\n",
    "chibadata3 = chibadata3[1:]\n",
    "chibadata4 = chibadata4[1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題２：「＊」を NaN に置き換え\n",
    "\n",
    "2番目の問題は四つのデータテーブルに「＊」の文字が入っているので、これを全て NaN (非数) に置き換える必要がある。自分で調べて実行してみよう。\n",
    "\n",
    "Hint: `.replace()` 関数を使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ４つのテーブルから「＊」を非数に置き換える\n",
    "chibadata1 = chibadata1.replace('*','0')\n",
    "chibadata2 = chibadata2.replace('*','0')\n",
    "chibadata3 = chibadata3.replace('*','0')\n",
    "chibadata4 = chibadata4.replace('*','0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ４つのデータを統合\n",
    "\n",
    "クリーンアップされた４つの統計データを一つに統合しよう。これはCSVデータなので pandas の `pd.concat()` 関数を使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chibadata = pd.concat([chibadata1,chibadata2,chibadata3,chibadata4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data info\n",
    "chibadata.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おっと！ここでもうひとつ問題発見！データが全て「object」タイプだ！これを数値に変換する必要がある。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データタイプ管理\n",
    "\n",
    "データがobjectだと数値ではないのでマップもチャートも作れません。\n",
    "\n",
    "このデータはカラムの数が多いので、ひとつひとつ変えて行くのは要領が悪いので、すべてのデータ型を一括で変更する方法を説明します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずはカラムをアウトプット\n",
    "chibadata.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変換が必要なのは「T0011000」で始まる変数のみなので、このリストの4番目以降になる。\n",
    "\n",
    "では4番目以降のカラムをアウトプットしよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4番目以降をアウトプット\n",
    "chibadata.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このカラムをテーブル形式で見る\n",
    "chibadata[chibadata.columns[4:]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では一気にobjectからfloatに変換してみよう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objectからfloatに変換\n",
    "chibadata[chibadata.columns[4:]].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いよいよ、元のデータと新しく変換したデータを入れ替える。ここで大事なのは元のデータの4番目以降だけを入れ替えること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のデータを入れ替える\n",
    "chibadata[chibadata.columns[4:]]=chibadata[chibadata.columns[4:]].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さ、必ずうまく行ったかどうかをチェックする。objectがfloatに変わってたら成功！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check!\n",
    "chibadata.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Mesh with Data\n",
    "\n",
    "ついに、結合されたメッシュ データ (chibamesh) と結合されたデータフレーム (chibadata) が完成しました。 最後のステップは、chibadata を chibamesh geodataframe に結合することです。\n",
    "\n",
    "これを行うには、それらを KEY_CODE id 列で結合します。 ただし、chibamesh KEY_CODE 列はオブジェクトであることに注意してください。 まずこれを float に変換しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY_CODEをfloatに\n",
    "chibamesh['KEY_CODE']=chibamesh['KEY_CODE'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マージを実行する！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data\n",
    "chibamesh = chibamesh.merge(chibadata, on='KEY_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check!\n",
    "chibamesh.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map time\n",
    "\n",
    "As you can see, creating a map is no easy feat. Data is almost always in need to be prepared, cleaned-up, and modified to make it \"map-ready.\" This process is called \"data-wrangling,\" and it represents an inevitable, yet extremely valuable skill in making legitimate and informative maps.\n",
    "\n",
    "Before we begin the mapping process, remember that your data needs to be reprojected to web mercator, which has a crs code of 3867. This is necessary in order to make your data compatible with the basemaps that are made available by the contextily library. \n",
    "\n",
    "ご覧のとおり、マップの作成は簡単ではありません。 データは、ほとんどの場合、「マップ対応」にするために準備、クリーンアップ、および変更する必要があります。 このプロセスは「データラングリング」と呼ばれ、正当で有益な地図を作成する上で避けられないものの、非常に貴重なスキルを表します。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project the data\n",
    "マッピング プロセスを開始する前に、データを Web メルカトルに再投影する必要があることに注意してください。Web メルカトルの crs コードは 3867 です。これは、データを contextily ライブラリで利用できるベースマップと互換性を持たせるために必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject to 3857 (web mercator)\n",
    "chibamesh = chibamesh.to_crs(3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a quick plot\n",
    "chibamesh.plot(column='T001100031')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題３：マップストーリーを作成\n",
    "\n",
    "メタデータを参照して、「ストーリーを伝える」一連の (4 つ以上の) コロプレス マップを作成します。 前週のラボ (Week09.ipynb) で使用した方法を使用してマップを作成します。\n",
    "\n",
    "要件：\n",
    "- タイトル\n",
    "- 伝説\n",
    "- ベースマップ\n",
    "- 各マップのストーリーを説明するマークダウン セル\n",
    "- 作成したマップをクラスギャラリーの[Googleスライド](https://docs.google.com/presentation/d/1oIwXESVpEQOlATKbUgNOGgSbz1IV63mDehEfBzGdDn0/edit#slide=id.g22aa073ab07_0_54)に追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人口マップ\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "chibamesh.plot(ax=ax,\n",
    "         column='T001100004',\n",
    "         legend=True,\n",
    "         cmap='autumn_r',\n",
    "         edgecolor='black',\n",
    "         linewidth=0.1,\n",
    "         alpha=0.8,\n",
    "        #  vmax=3000,\n",
    "         legend_kwds={'label': \"０～１４歳人口　総数人\",'shrink': 0.6, 'orientation': \"horizontal\", 'pad': 0.01}\n",
    ")\n",
    "\n",
    "# マップの範囲を chibamesh の境界に設定\n",
    "ax.set_xlim(chibamesh.total_bounds[0], chibamesh.total_bounds[2])\n",
    "ax.set_ylim(chibamesh.total_bounds[1], chibamesh.total_bounds[3])\n",
    "\n",
    "# 軸を非表示にする\n",
    "ax.axis('off')\n",
    "\n",
    "# タイトル\n",
    "ax.set_title('０～１４歳人口　総数人',fontsize=24,pad=20);\n",
    "\n",
    "# ベースマップを追加\n",
    "# cx.add_basemap(ax,source='https://cyberjapandata.gsi.go.jp/xyz/pale/{z}/{x}/{y}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chibamesh[chibamesh['T001100001']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化された値を計算する\n",
    "chibamesh['Percent0_14'] = chibamesh['T001100004'] / chibamesh['T001100001']*100\n",
    "\n",
    "# コロプレスマップをプロットする\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "chibamesh.plot(ax=ax,\n",
    "               column='Percent0_14',\n",
    "               legend=True,\n",
    "               cmap='RdYlGn_r',\n",
    "               edgecolor='black',\n",
    "               linewidth=0.1,\n",
    "               alpha=0.8,\n",
    "               vmax=20,\n",
    "               legend_kwds={'label': '０～１４歳人口　総数人％', 'shrink': 0.6, 'orientation': 'horizontal', 'pad': 0.01}\n",
    "              )\n",
    "\n",
    "# マップの範囲を chibamesh の境界に設定する\n",
    "ax.set_xlim(chibamesh.total_bounds[0], chibamesh.total_bounds[2])\n",
    "ax.set_ylim(chibamesh.total_bounds[1], chibamesh.total_bounds[3])\n",
    "\n",
    "# 軸を非表示にする\n",
    "ax.axis('off')\n",
    "\n",
    "# タイトルを設定する\n",
    "ax.set_title('０～１４歳の子供はどこにいるの？', fontsize=24, pad=20)\n",
    "\n",
    "# ベースマップを追加する\n",
    "# cx.add_basemap(ax, source='https://cyberjapandata.gsi.go.jp/xyz/pale/{z}/{x}/{y}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化された値を計算する\n",
    "chibamesh['Percent75over'] = chibamesh['T001100022'] / chibamesh['T001100001']*100\n",
    "\n",
    "# コロプレスマップをプロットする\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "chibamesh.plot(ax=ax,\n",
    "               column='Percent75over',\n",
    "               legend=True,\n",
    "               cmap='RdYlGn_r',\n",
    "               edgecolor='black',\n",
    "               linewidth=0.1,\n",
    "               alpha=0.8,\n",
    "               vmax=30,\n",
    "               legend_kwds={'label': '７５歳以上人口　総数', 'shrink': 0.6, 'orientation': 'horizontal', 'pad': 0.01}\n",
    "              )\n",
    "\n",
    "# マップの範囲を chibamesh の境界に設定する\n",
    "ax.set_xlim(chibamesh.total_bounds[0], chibamesh.total_bounds[2])\n",
    "ax.set_ylim(chibamesh.total_bounds[1], chibamesh.total_bounds[3])\n",
    "\n",
    "# 軸を非表示にする\n",
    "ax.axis('off')\n",
    "\n",
    "# タイトルを設定する\n",
    "ax.set_title('高齢者はどこにいるの？', fontsize=24, pad=20)\n",
    "\n",
    "# ベースマップを追加する\n",
    "# cx.add_basemap(ax, source='https://cyberjapandata.gsi.go.jp/xyz/pale/{z}/{x}/{y}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
